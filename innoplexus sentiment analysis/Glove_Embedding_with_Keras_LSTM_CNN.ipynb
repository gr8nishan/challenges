{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove_Embedding_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3zIRa-I1j_x",
        "colab_type": "text"
      },
      "source": [
        "## Downloading Glove Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dae-c-QRVXhX",
        "colab_type": "code",
        "outputId": "b5360688-9fd3-48c8-d647-d09ef2934283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
        "!apt install unzip\n",
        "!unzip \"glove.42B.300d.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-29 15:08:53--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
            "--2019-07-29 15:08:53--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2019-07-29 15:08:53--  http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  39.3MB/s    in 46s     \n",
            "\n",
            "2019-07-29 15:09:40 (38.8 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Archive:  glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl0iKOj71pjn",
        "colab_type": "text"
      },
      "source": [
        "## Convert Glove Embedding to Word2Vec Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmuuhOT809a_",
        "colab_type": "code",
        "outputId": "ba80bf8c-d6dd-47e4-cdd3-694c8b5afd32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!pip install nlppreprocess"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlppreprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/84/c2/23535011b283941983aa04e20a5acf30cf3f52347f4533b2a32ebf4201c1/nlppreprocess-1.0.1.tar.gz\n",
            "Building wheels for collected packages: nlppreprocess\n",
            "  Building wheel for nlppreprocess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/dd/cd/9b3abfc7c421819567ae5530dc0a8e4a4776e14034e92add76\n",
            "Successfully built nlppreprocess\n",
            "Installing collected packages: nlppreprocess\n",
            "Successfully installed nlppreprocess-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6zvXrathO_q",
        "colab_type": "code",
        "outputId": "b83159a7-449d-42f2-92ac-ab606bc0fc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNvMFEolJuSi",
        "colab_type": "code",
        "outputId": "166e140c-262e-4224-f6be-ed429a28ff0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove2word2vec(glove_input_file=\"glove.42B.300d.txt\", word2vec_output_file=\"gensim_glove_vectors.txt\")\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H7BS3J61Zuw",
        "colab_type": "text"
      },
      "source": [
        "## Installing nlppreprocess package (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRP4ZeLQ0-OQ",
        "colab_type": "text"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUxA-cMK1DYX",
        "colab_type": "text"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K_SfQJFVvmT",
        "colab_type": "code",
        "outputId": "4e136aa3-345e-4c34-827e-9acb3b43c610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nlppreprocess import NLP\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, LSTM, Bidirectional, Dropout, SpatialDropout1D, Embedding, GlobalAveragePooling1D,GRU,Conv1D,Activation\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06tOcuV41OcH",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXN-vUCNA6pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/innoplexus/test_tOlRoBf.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaWmecL5V-li",
        "colab_type": "code",
        "outputId": "0d9e68fd-bb21-4993-c6ce-ee220444e4cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train = pd.read_csv('/content/drive/My Drive/innoplexus/train_F3WbcTw.csv')\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
              "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
              "      <td>I can completely understand why you’d want to ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
              "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
              "      <td>fingolimod</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
              "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
              "      <td>ocrevus</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
              "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
              "      <td>gilenya</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ... sentiment\n",
              "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0  ...         2\n",
              "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4  ...         2\n",
              "2  fe809672251f6bd0d986e00380f48d047c7e7b76  ...         2\n",
              "3  bd22104dfa9ec80db4099523e03fae7a52735eb6  ...         2\n",
              "4  b227688381f9b25e5b65109dd00f7f895e838249  ...         1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJxOogM8b5Hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['text'] = df_train['text'].str.lower()\n",
        "df_test['text'] = df_test['text'].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4osC0uLLEjV",
        "colab_type": "code",
        "outputId": "d0292376-da3f-408d-b475-e9658d27fbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df_train.groupby('sentiment').size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "0     617\n",
              "1     837\n",
              "2    3825\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6nzgoW7KQUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ranges = [0,10,50,100,150,200,300,400,500,600,700,1000,1500,2000,5000,10000,20000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UueoiTYZ2FF4",
        "colab_type": "code",
        "outputId": "c5691451-1a0a-446f-dea9-b7e9db83c830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train = df_train[['text', 'sentiment']]\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>autoimmune diseases tend to come in clusters. ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can completely understand why you’d want to ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>interesting that it only targets s1p-1/5 recep...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>very interesting, grand merci. now i wonder wh...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hi everybody, my latest mri results for brain ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  autoimmune diseases tend to come in clusters. ...          2\n",
              "1  i can completely understand why you’d want to ...          2\n",
              "2  interesting that it only targets s1p-1/5 recep...          2\n",
              "3  very interesting, grand merci. now i wonder wh...          2\n",
              "4  hi everybody, my latest mri results for brain ...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J302twmg2JMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = to_categorical(df_train['sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvHh-WH_yyW4",
        "colab_type": "code",
        "outputId": "e44e8ffe-2a5f-4cda-a78c-2e2e15ced172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3uZE6IIcCac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obj = NLP(\n",
        "       replace_words=True,\n",
        "       remove_stopwords=True,\n",
        "       remove_numbers=True,\n",
        "        remove_punctuations=True\n",
        "       )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edspS5LJcOVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['text'] = df_train['text'].apply(obj.process).values\n",
        "df_train['text'] = df_train['text'].apply(obj.process).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u91TyVRPXU5S",
        "colab_type": "code",
        "outputId": "52daff38-2c46-4cdf-d8ff-0e22ad7b3159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYV9WBvQXeLQ",
        "colab_type": "code",
        "outputId": "5e9f7921-939f-40ed-fc33-e7c67308a9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW5Bxd6sW48M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
        "\n",
        "#df_train['text'] = pd.DataFrame(['this was cheesy', 'she likes these books', 'wow this is great'], columns=['text'])\n",
        "df_train['text_lemmatized'] = df_train['text'].apply(lemmatize_text)\n",
        "df_test['text_lemmatized'] = df_test['text'].apply(lemmatize_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPNxrfUtt61C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def join_text(words):\n",
        "  text = \" \"\n",
        "  for w in words:\n",
        "    if(len(w) > 2):\n",
        "      text = text + w + \" \"\n",
        "  text = text.strip()\n",
        "  return text\n",
        "  \n",
        "df_train['text_lemmatized'] = df_train['text_lemmatized'].apply(join_text)\n",
        "df_test['text_lemmatized'] = df_test['text_lemmatized'].apply(join_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfpEq6ZDXIVN",
        "colab_type": "code",
        "outputId": "3f242368-8098-4cf0-eca5-4341deed61c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df_train['text_lemmatized'][2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'interesting only target receptor rather than like fingolimod hoping soon see what aes and saes yes not sure what mean exactly quote nine patient reported serious adverse event and serious adverse event reported more than patient and new safety signal occurred compared with bold study there patient reporting saes how can stated serious adverse event reported more than patient maybe not read right maybe there misprint very pleased something being developed spms and encouraging siponimod not linger very long body'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifgRDdjWNd5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = []\n",
        "for index, row in df_train.iterrows():\n",
        "  text = row['text_lemmatized']\n",
        "  k = len(text.split())\n",
        "  res.append(k)\n",
        "\n",
        "df_train['lenoftext'] = res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho3XkgLrKyhk",
        "colab_type": "code",
        "outputId": "7fa3b065-959b-4151-abdd-3cafb3e85dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "source": [
        "df_train.groupby(pd.cut(df_train['lenoftext'], ranges)).count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_lemmatized</th>\n",
              "      <th>lenoftext</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lenoftext</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(0, 10]</th>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(10, 50]</th>\n",
              "      <td>1324</td>\n",
              "      <td>1324</td>\n",
              "      <td>1324</td>\n",
              "      <td>1324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(50, 100]</th>\n",
              "      <td>1388</td>\n",
              "      <td>1388</td>\n",
              "      <td>1388</td>\n",
              "      <td>1388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(100, 150]</th>\n",
              "      <td>730</td>\n",
              "      <td>730</td>\n",
              "      <td>730</td>\n",
              "      <td>730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(150, 200]</th>\n",
              "      <td>461</td>\n",
              "      <td>461</td>\n",
              "      <td>461</td>\n",
              "      <td>461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(200, 300]</th>\n",
              "      <td>428</td>\n",
              "      <td>428</td>\n",
              "      <td>428</td>\n",
              "      <td>428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(300, 400]</th>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(400, 500]</th>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(500, 600]</th>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(600, 700]</th>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(700, 1000]</th>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(1000, 1500]</th>\n",
              "      <td>134</td>\n",
              "      <td>134</td>\n",
              "      <td>134</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(1500, 2000]</th>\n",
              "      <td>41</td>\n",
              "      <td>41</td>\n",
              "      <td>41</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(2000, 5000]</th>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(5000, 10000]</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(10000, 20000]</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                text  sentiment  text_lemmatized  lenoftext\n",
              "lenoftext                                                  \n",
              "(0, 10]          121        121              121        121\n",
              "(10, 50]        1324       1324             1324       1324\n",
              "(50, 100]       1388       1388             1388       1388\n",
              "(100, 150]       730        730              730        730\n",
              "(150, 200]       461        461              461        461\n",
              "(200, 300]       428        428              428        428\n",
              "(300, 400]       229        229              229        229\n",
              "(400, 500]       125        125              125        125\n",
              "(500, 600]        75         75               75         75\n",
              "(600, 700]        52         52               52         52\n",
              "(700, 1000]      111        111              111        111\n",
              "(1000, 1500]     134        134              134        134\n",
              "(1500, 2000]      41         41               41         41\n",
              "(2000, 5000]      48         48               48         48\n",
              "(5000, 10000]     12         12               12         12\n",
              "(10000, 20000]     0          0                0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YVTjopaLuRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = []\n",
        "for index, row in df_test.iterrows():\n",
        "  text = row['text_lemmatized']\n",
        "  k = len(text.split())\n",
        "  res.append(k)\n",
        "df_test['lenoftext'] = res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJzQeyA1L4mg",
        "colab_type": "code",
        "outputId": "4d772045-97e5-4c5e-bc76-085ddf4c01af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "source": [
        "df_test.groupby(pd.cut(df_test['lenoftext'], ranges)).count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "      <th>text_lemmatized</th>\n",
              "      <th>lenoftext</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lenoftext</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(0, 10]</th>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(10, 50]</th>\n",
              "      <td>534</td>\n",
              "      <td>534</td>\n",
              "      <td>534</td>\n",
              "      <td>534</td>\n",
              "      <td>534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(50, 100]</th>\n",
              "      <td>719</td>\n",
              "      <td>719</td>\n",
              "      <td>719</td>\n",
              "      <td>719</td>\n",
              "      <td>719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(100, 150]</th>\n",
              "      <td>466</td>\n",
              "      <td>466</td>\n",
              "      <td>466</td>\n",
              "      <td>466</td>\n",
              "      <td>466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(150, 200]</th>\n",
              "      <td>283</td>\n",
              "      <td>283</td>\n",
              "      <td>283</td>\n",
              "      <td>283</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(200, 300]</th>\n",
              "      <td>296</td>\n",
              "      <td>296</td>\n",
              "      <td>296</td>\n",
              "      <td>296</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(300, 400]</th>\n",
              "      <td>145</td>\n",
              "      <td>145</td>\n",
              "      <td>145</td>\n",
              "      <td>145</td>\n",
              "      <td>145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(400, 500]</th>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(500, 600]</th>\n",
              "      <td>62</td>\n",
              "      <td>62</td>\n",
              "      <td>62</td>\n",
              "      <td>62</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(600, 700]</th>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(700, 1000]</th>\n",
              "      <td>73</td>\n",
              "      <td>73</td>\n",
              "      <td>73</td>\n",
              "      <td>73</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(1000, 1500]</th>\n",
              "      <td>85</td>\n",
              "      <td>85</td>\n",
              "      <td>85</td>\n",
              "      <td>85</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(1500, 2000]</th>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(2000, 5000]</th>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(5000, 10000]</th>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(10000, 20000]</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                unique_hash  text  drug  text_lemmatized  lenoftext\n",
              "lenoftext                                                          \n",
              "(0, 10]                  29    29    29               29         29\n",
              "(10, 50]                534   534   534              534        534\n",
              "(50, 100]               719   719   719              719        719\n",
              "(100, 150]              466   466   466              466        466\n",
              "(150, 200]              283   283   283              283        283\n",
              "(200, 300]              296   296   296              296        296\n",
              "(300, 400]              145   145   145              145        145\n",
              "(400, 500]               98    98    98               98         98\n",
              "(500, 600]               62    62    62               62         62\n",
              "(600, 700]               35    35    35               35         35\n",
              "(700, 1000]              73    73    73               73         73\n",
              "(1000, 1500]             85    85    85               85         85\n",
              "(1500, 2000]             38    38    38               38         38\n",
              "(2000, 5000]             44    44    44               44         44\n",
              "(5000, 10000]            15    15    15               15         15\n",
              "(10000, 20000]            1     1     1                1          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poxa_T1CcIzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_train['text_lemmatized']\n",
        "X_test = df_test['text_lemmatized']\n",
        "#Y_test = df_test['Sentiment']\n",
        "Y_train = df_train['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdDFBpOdeYQI",
        "colab_type": "code",
        "outputId": "09ddf18e-6a28-4499-fc3a-a4da08a4c60a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X_train[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'interesting only target receptor rather than like fingolimod hoping soon see what aes and saes yes not sure what mean exactly quote nine patient reported serious adverse event and serious adverse event reported more than patient and new safety signal occurred compared with bold study there patient reporting saes how can stated serious adverse event reported more than patient maybe not read right maybe there misprint very pleased something being developed spms and encouraging siponimod not linger very long body'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_W6MBlt10Il",
        "colab_type": "text"
      },
      "source": [
        "## Encoding and padding training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCaFsc_f0t8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 350\n",
        "num_words = max_features = MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 300\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T05M2mpbaQYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#max_features = 10000\n",
        "#max_len = 40\n",
        "\n",
        "docs = np.concatenate((X_train, X_test))\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features,oov_token=True)\n",
        "tokenizer.fit_on_texts(docs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBUuWSa3dYlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_train_pad = pad_sequences(tokenizer.texts_to_sequences(X_train),maxlen = MAX_SEQUENCE_LENGTH,padding='post')\n",
        "x_test_pad = pad_sequences(tokenizer.texts_to_sequences(X_test),maxlen = MAX_SEQUENCE_LENGTH,padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-2obhjgHaA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = '/content'\n",
        "GLOVE_DIR = '/content/glove.42B.300d.txt'\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 500\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 300\n",
        "VALIDATION_SPLIT = 0.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu3Yoi8jHtqx",
        "colab_type": "code",
        "outputId": "a4a9fcc8-8fab-4631-e486-22752b23297d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "\n",
        "\n",
        "\n",
        "# first, build index mapping words in the embeddings set\n",
        "# to their embedding vector\n",
        "\n",
        "print('Indexing word vectors.')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(GLOVE_DIR) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "\n",
        "\n",
        "# finally, vectorize the text samples into a 2D integer tensor\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 1917494 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hIhaozfFSQH",
        "colab_type": "code",
        "outputId": "48544d86-0175-44c1-81f3-f5f2f8374ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "#max_features = 10000\n",
        "#max_len = 40\n",
        "\n",
        "docs = np.concatenate((X_train, X_test))\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(docs)\n",
        "#sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "x_train_pad = pad_sequences(X_train_tokens,maxlen = MAX_SEQUENCE_LENGTH,padding='post')\n",
        "x_test_pad = pad_sequences(X_test_tokens,maxlen = MAX_SEQUENCE_LENGTH,padding='post')\n",
        "#data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 42962 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaF1L4mOFdMY",
        "colab_type": "code",
        "outputId": "020d643d-b305-40c2-eb9e-9332350d148e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Preparing embedding matrix.')\n",
        "\n",
        "# prepare embedding matrix\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing embedding matrix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QrGjqU_EsPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_NhKgrxPybu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n",
        "\n",
        "def f1_loss(y_true, y_pred):\n",
        "    \n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return 1 - K.mean(f1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7EWrk-EklN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train a 1D convnet with global maxpooling\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu')(x)\n",
        "x = MaxPooling1D(5)(x)\n",
        "x = Conv1D(128, 5, activation='relu')(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "preds = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss=f1_loss, optimizer='adam', metrics=['acc',f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUoAT7UNKRBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYV980en-i5N",
        "colab_type": "code",
        "outputId": "b8ca8bf7-c999-4ad2-df94-a2db5f8da689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "model = Sequential()\n",
        "model.add(glove_model.get_keras_embedding())\n",
        "model.add(GRU(units=32,dropout=0.2,recurrent_dropout=0.2))\n",
        "model.add(Dense(3,activation='sigmoid'))\n",
        "model.summary()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel = Sequential()\\nmodel.add(glove_model.get_keras_embedding())\\nmodel.add(GRU(units=32,dropout=0.2,recurrent_dropout=0.2))\\nmodel.add(Dense(3,activation='sigmoid'))\\nmodel.summary()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46OETIYz2EKQ",
        "colab_type": "text"
      },
      "source": [
        "## Create Model\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM-DrbGOazf2",
        "colab_type": "code",
        "outputId": "75a4768d-8dae-43fb-a562-134b97131106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(glove_model.get_keras_embedding())\n",
        "model.add(Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='sigmoid'))\n",
        "#model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0729 15:37:43.325032 140664152160128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0729 15:37:43.368337 140664152160128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0729 15:37:43.381648 140664152160128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0729 15:37:43.393718 140664152160128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0729 15:37:43.394804 140664152160128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0729 15:37:52.023193 140664152160128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DySUfsna0Psh",
        "colab_type": "code",
        "outputId": "48eb8d29-46b0-4100-e344-5cda627b60c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "model.compile(loss=f1_loss, optimizer='adam', metrics=['acc',f1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0729 15:38:03.499581 140664152160128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0729 15:38:03.549442 140664152160128 deprecation.py:323] From <ipython-input-35-96bff58e4672>:29: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoiMcFb6Emcj",
        "colab_type": "code",
        "outputId": "a2c2408c-90d0-4d87-8996-cc1e11d05903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "model.fit(x_train_pad, Y,batch_size=32, epochs=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "5279/5279 [==============================] - 198s 38ms/step - loss: 0.5675 - acc: 0.6905 - f1: 0.4358\n",
            "Epoch 2/15\n",
            "5279/5279 [==============================] - 194s 37ms/step - loss: 0.5628 - acc: 0.7011 - f1: 0.4373\n",
            "Epoch 3/15\n",
            "5279/5279 [==============================] - 192s 36ms/step - loss: 0.5632 - acc: 0.6952 - f1: 0.4368\n",
            "Epoch 4/15\n",
            "5279/5279 [==============================] - 194s 37ms/step - loss: 0.5621 - acc: 0.7058 - f1: 0.4379\n",
            "Epoch 5/15\n",
            "5279/5279 [==============================] - 192s 36ms/step - loss: 0.5607 - acc: 0.7039 - f1: 0.4397\n",
            "Epoch 6/15\n",
            "5279/5279 [==============================] - 192s 36ms/step - loss: 0.5600 - acc: 0.6914 - f1: 0.4399\n",
            "Epoch 7/15\n",
            "5279/5279 [==============================] - 193s 37ms/step - loss: 0.5599 - acc: 0.6766 - f1: 0.4402\n",
            "Epoch 8/15\n",
            "5279/5279 [==============================] - 195s 37ms/step - loss: 0.5597 - acc: 0.6755 - f1: 0.4406\n",
            "Epoch 9/15\n",
            "5279/5279 [==============================] - 196s 37ms/step - loss: 0.5596 - acc: 0.6969 - f1: 0.4407\n",
            "Epoch 10/15\n",
            "5279/5279 [==============================] - 193s 37ms/step - loss: 0.5608 - acc: 0.6910 - f1: 0.4389\n",
            "Epoch 11/15\n",
            "5279/5279 [==============================] - 194s 37ms/step - loss: 0.5601 - acc: 0.6783 - f1: 0.4400\n",
            "Epoch 12/15\n",
            "5279/5279 [==============================] - 193s 37ms/step - loss: 0.5595 - acc: 0.6316 - f1: 0.4405\n",
            "Epoch 13/15\n",
            "5279/5279 [==============================] - 195s 37ms/step - loss: 0.5588 - acc: 0.6556 - f1: 0.4415\n",
            "Epoch 14/15\n",
            "5279/5279 [==============================] - 196s 37ms/step - loss: 0.5593 - acc: 0.6327 - f1: 0.4409\n",
            "Epoch 15/15\n",
            "5279/5279 [==============================] - 195s 37ms/step - loss: 0.5595 - acc: 0.6611 - f1: 0.4404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee612ab940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bR7H8ew2MZ4",
        "colab_type": "text"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdc-m36U2P9x",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCgW-R48qzEX",
        "colab_type": "code",
        "outputId": "3a0fdad2-7121-4e13-9c13-b8c3e2f7f18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res = model.predict(x_test_pad,batch_size=32,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2924/2924 [==============================] - 29s 10ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weVlBgbLy_fG",
        "colab_type": "code",
        "outputId": "87e64877-a337-4dea-838d-1204a3f62e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2924, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmKl7ownESi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df_final = DataFrame()\n",
        "final_sentiment = []\n",
        "for k in range(len(res)):\n",
        "  final_sentiment.append(np.argmax(res[k]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJXWWieEGf_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final= pd.read_csv('/content/drive/My Drive/innoplexus/test_tOlRoBf.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S-6MYubGtHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final['sentiment'] = final_sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdaOb8XHIb9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = df_final[['unique_hash','sentiment']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6fkbhDbHDSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final.to_csv('/content/submission_15.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twbDyIkVISpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}